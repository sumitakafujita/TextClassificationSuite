{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "\n",
    "# Text Classification PoC v2\n",
    "- SentenceTransformer: `intfloat/multilingual-e5-small`（instruction tuned）で高品質な埋め込みを取得。\n",
    "- 5-fold Stratified CV + hold-out で SVM/LogReg/MLP/LightGBM/Bagging を比較し、Optuna で主要モデルをチューニング。\n",
    "- カテゴリ名の埋め込みとのコサイン類似度や確信度モニタリング、類似問い合わせ抽出など運用要件をPoC化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Purpose: Import dependencies, set constants/logging, and configure deterministic behavior for reproducibility.\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Iterable, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from lightgbm import LGBMClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "from sklearn.ensemble import BaggingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "DATA_PATH = Path(\"data/data.csv\")\n",
    "# EMBED_MODEL_NAME = \"intfloat/multilingual-e5-small\"\n",
    "EMBED_MODEL_NAME = \"stsb-xlm-r-multilingual\"\n",
    "E5_INSTRUCTION = \"query: \"\n",
    "STRUCTURED_OUTPUT_MODEL = \"gpt-4o-mini\"\n",
    "STRUCTURED_SAMPLE_SIZE = 5\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "pl.enable_string_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Purpose: Provide data loading helpers built on top of Polars LazyFrame for scalable ingestion.\n",
    "def load_lazy_dataset(csv_path: Path) -> pl.LazyFrame:\n",
    "    \"\"\"Return a Polars LazyFrame scanning the CSV without materializing rows.\"\"\"\n",
    "    return pl.scan_csv(csv_path)\n",
    "\n",
    "\n",
    "def preview_lazyframe(lazy_frame: pl.LazyFrame, sample_size: int = 5) -> pl.DataFrame:\n",
    "    \"\"\"Collect a small sample to inspect schema/values while keeping the query lazy.\"\"\"\n",
    "    return lazy_frame.head(sample_size).collect()\n",
    "\n",
    "\n",
    "def materialize_dataset(lazy_frame: pl.LazyFrame) -> pd.DataFrame:\n",
    "    \"\"\"Materialize the LazyFrame into a Pandas DataFrame for compatibility with sklearn.\"\"\"\n",
    "    return lazy_frame.collect().to_pandas()\n",
    "\n",
    "\n",
    "def encode_labels(\n",
    "    df: pd.DataFrame,\n",
    "    label_column: str = \"category\",\n",
    "    new_column: str = \"category_id\",\n",
    ") -> Tuple[pd.DataFrame, preprocessing.LabelEncoder]:\n",
    "    \"\"\"Encode string labels into integers and append them as a new column.\"\"\"\n",
    "    encoded_df = df.copy()\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoded_df[new_column] = encoder.fit_transform(encoded_df[label_column])\n",
    "    return encoded_df, encoder\n",
    "\n",
    "\n",
    "def summarize_categories(\n",
    "    df: pd.DataFrame,\n",
    "    category_name_col: str = \"category\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Return counts and ratios per category for quick EDA.\"\"\"\n",
    "    summary = (\n",
    "        df[category_name_col]\n",
    "        .value_counts()\n",
    "        .rename(\"count\")\n",
    "        .to_frame()\n",
    "        .assign(ratio=lambda frame: frame[\"count\"] / frame[\"count\"].sum())\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": category_name_col})\n",
    "    )\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>アイデアＩＤ</th><th>アイデアタイトル</th><th>text</th><th>category</th><th></th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>441</td><td>&quot;フレックスタイム制の導入による働き方改革&quot;</td><td>&quot;現行の「スライド勤務」に加えて、新たに「フレックスタイム制度…</td><td>&quot;福利厚生・制度&quot;</td><td>null</td></tr><tr><td>468</td><td>&quot;フレキシブルワーク～フレックスタイム制＆週休３日の進化系～&quot;</td><td>&quot;フルフレックス制とコアタイム制のハイブリッド型勤務制度の導入…</td><td>&quot;福利厚生・制度&quot;</td><td>null</td></tr><tr><td>1634</td><td>&quot;ホワイトボードをコミュニケーションツールにしませんか？&quot;</td><td>&quot;在席や外出を確認するＷＢを、担当者にマウスをあてると顔写真や…</td><td>&quot;総務&quot;</td><td>null</td></tr><tr><td>1737</td><td>&quot;人となりがわかるホワイトボード&quot;</td><td>&quot;ホワイトボードは社員の基本情報がすぐにわかり、便利なツールで…</td><td>&quot;総務&quot;</td><td>null</td></tr><tr><td>349</td><td>&quot;ホワイトボードの進化版！\r\n",
       "コミュニケーションボードの開発！&quot;</td><td>&quot;現状のホワイトボードでは誰がどんな仕事をしているか分かりませ…</td><td>&quot;総務&quot;</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────┬─────────────────────────────┬─────────────────────────────┬────────────────┬──────┐\n",
       "│ アイデアＩＤ ┆ アイデアタイトル            ┆ text                        ┆ category       ┆      │\n",
       "│ ---          ┆ ---                         ┆ ---                         ┆ ---            ┆ ---  │\n",
       "│ i64          ┆ str                         ┆ str                         ┆ str            ┆ str  │\n",
       "╞══════════════╪═════════════════════════════╪═════════════════════════════╪════════════════╪══════╡\n",
       "│ 441          ┆ フレックスタイム制の導入に  ┆ 現行の「スライド勤務」に加  ┆ 福利厚生・制度 ┆ null │\n",
       "│              ┆ よる働き方改革              ┆ えて、新たに「フレックスタ  ┆                ┆      │\n",
       "│              ┆                             ┆ イム制度…                   ┆                ┆      │\n",
       "│ 468          ┆ フレキシブルワーク～フレッ  ┆ フルフレックス制とコアタイ  ┆ 福利厚生・制度 ┆ null │\n",
       "│              ┆ クスタイム制＆週休３日の進  ┆ ム制のハイブリッド型勤務制  ┆                ┆      │\n",
       "│              ┆ 化系～                      ┆ 度の導入…                   ┆                ┆      │\n",
       "│ 1634         ┆ ホワイトボードをコミュニケ  ┆ 在席や外出を確認するＷＢを  ┆ 総務           ┆ null │\n",
       "│              ┆ ーションツールにしませんか  ┆ 、担当者にマウスをあてると  ┆                ┆      │\n",
       "│              ┆ ？                          ┆ 顔写真や…                   ┆                ┆      │\n",
       "│ 1737         ┆ 人となりがわかるホワイトボ  ┆ ホワイトボードは社員の基本  ┆ 総務           ┆ null │\n",
       "│              ┆ ード                        ┆ 情報がすぐにわかり、便利な  ┆                ┆      │\n",
       "│              ┆                             ┆ ツールで…                   ┆                ┆      │\n",
       "│ 349          ┆ ホワイトボードの進化版！\n",
       "   ┆ 現状のホワイトボードでは誰  ┆ 総務           ┆ null │\n",
       "│              ┆ コミュニケーションボードの  ┆ がどんな仕事をしているか分  ┆                ┆      │\n",
       "│              ┆ 開発！                      ┆ かりませ…                   ┆                ┆      │\n",
       "└──────────────┴─────────────────────────────┴─────────────────────────────┴────────────────┴──────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Purpose: Load the dataset lazily, preview it, and persist a Pandas copy with encoded labels for modeling.\n",
    "lazy_dataset = load_lazy_dataset(DATA_PATH)\n",
    "preview_lazyframe(lazy_dataset, sample_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>福利厚生・制度</td>\n",
       "      <td>292</td>\n",
       "      <td>0.226884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>総務</td>\n",
       "      <td>192</td>\n",
       "      <td>0.149184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>施工</td>\n",
       "      <td>178</td>\n",
       "      <td>0.138306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>営業</td>\n",
       "      <td>131</td>\n",
       "      <td>0.101787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>設計</td>\n",
       "      <td>125</td>\n",
       "      <td>0.097125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>サービス</td>\n",
       "      <td>110</td>\n",
       "      <td>0.085470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ESG</td>\n",
       "      <td>102</td>\n",
       "      <td>0.079254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>新規事業</td>\n",
       "      <td>69</td>\n",
       "      <td>0.053613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>商品開発</td>\n",
       "      <td>64</td>\n",
       "      <td>0.049728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>生産</td>\n",
       "      <td>24</td>\n",
       "      <td>0.018648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category  count     ratio\n",
       "0  福利厚生・制度    292  0.226884\n",
       "1       総務    192  0.149184\n",
       "2       施工    178  0.138306\n",
       "3       営業    131  0.101787\n",
       "4       設計    125  0.097125\n",
       "5     サービス    110  0.085470\n",
       "6      ESG    102  0.079254\n",
       "7     新規事業     69  0.053613\n",
       "8     商品開発     64  0.049728\n",
       "9       生産     24  0.018648"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Purpose: Materialize the dataset, attach numeric labels, and summarize category balance for reference.\n",
    "records_df, label_encoder = encode_labels(materialize_dataset(lazy_dataset))\n",
    "category_summary = summarize_categories(records_df)\n",
    "category_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bb2070",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Purpose: Configure OpenAI structured-output helper so we can probe a few samples early.\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise EnvironmentError(\n",
    "        f\"{OPENAI_API_KEY} is not set. Export your OpenAI API key before running the structured-output probe.\"\n",
    "    )\n",
    "\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "# Pydantic スキーマ（LLMの出力をここにパース）\n",
    "class Classification(BaseModel):\n",
    "    record_id: str = Field(..., description=\"ID of the record from the input list\")\n",
    "    category: str = Field(..., description=\"One of the allowed categories\")\n",
    "    reason: str = Field(..., description=\"Why this category was selected (Japanese)\")\n",
    "\n",
    "\n",
    "class ClassificationBatch(BaseModel):\n",
    "    classifications: List[Classification]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c61e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 19:12:20,349 INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>llm_category</th>\n",
       "      <th>llm_reason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>現行の「スライド勤務」に加えて、新たに「フレックスタイム制度」を導入を目指します。\\r\\nコ...</td>\n",
       "      <td>福利厚生・制度</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>フルフレックス制とコアタイム制のハイブリッド型勤務制度の導入を提案します。１週間・1か月単位...</td>\n",
       "      <td>福利厚生・制度</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>在席や外出を確認するＷＢを、担当者にマウスをあてると顔写真や趣味などが見えれば、業務の話のつ...</td>\n",
       "      <td>総務</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ホワイトボードは社員の基本情報がすぐにわかり、便利なツールですが、面識のない人は顔や人となり...</td>\n",
       "      <td>総務</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>現状のホワイトボードでは誰がどんな仕事をしているか分かりません！！\\r\\nコミュニケーション...</td>\n",
       "      <td>総務</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Teamsで海外の人と現場の工事状況や安全パトロールを実況します。\\r\\nもしリアルタイムで...</td>\n",
       "      <td>施工</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>小人数グループでの気軽に話せるＷＥＢ研修の継続的定期開催と実際に申請担当に同行し物件の役所調...</td>\n",
       "      <td>設計</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>単純に可動棚を設けるだけでなく、可動棚に何を収納するかまで提案された事例やマニュアルを作るこ...</td>\n",
       "      <td>設計</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>業務の中で「いつもくりかえし行う同じ作業」削減する取り組みです。中でもCAD作業・作図作業に...</td>\n",
       "      <td>設計</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CANVAS、MicrosoftExchange他、様々なソフトを使って情報・業務管理を行っ...</td>\n",
       "      <td>総務</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text category llm_category  \\\n",
       "id                                                                            \n",
       "0   現行の「スライド勤務」に加えて、新たに「フレックスタイム制度」を導入を目指します。\\r\\nコ...  福利厚生・制度         <NA>   \n",
       "1   フルフレックス制とコアタイム制のハイブリッド型勤務制度の導入を提案します。１週間・1か月単位...  福利厚生・制度         <NA>   \n",
       "2   在席や外出を確認するＷＢを、担当者にマウスをあてると顔写真や趣味などが見えれば、業務の話のつ...       総務         <NA>   \n",
       "3   ホワイトボードは社員の基本情報がすぐにわかり、便利なツールですが、面識のない人は顔や人となり...       総務         <NA>   \n",
       "4   現状のホワイトボードでは誰がどんな仕事をしているか分かりません！！\\r\\nコミュニケーション...       総務         <NA>   \n",
       "..                                                ...      ...          ...   \n",
       "95  Teamsで海外の人と現場の工事状況や安全パトロールを実況します。\\r\\nもしリアルタイムで...       施工         <NA>   \n",
       "96  小人数グループでの気軽に話せるＷＥＢ研修の継続的定期開催と実際に申請担当に同行し物件の役所調...       設計         <NA>   \n",
       "97  単純に可動棚を設けるだけでなく、可動棚に何を収納するかまで提案された事例やマニュアルを作るこ...       設計         <NA>   \n",
       "98  業務の中で「いつもくりかえし行う同じ作業」削減する取り組みです。中でもCAD作業・作図作業に...       設計         <NA>   \n",
       "99  CANVAS、MicrosoftExchange他、様々なソフトを使って情報・業務管理を行っ...       総務         <NA>   \n",
       "\n",
       "   llm_reason  \n",
       "id             \n",
       "0        <NA>  \n",
       "1        <NA>  \n",
       "2        <NA>  \n",
       "3        <NA>  \n",
       "4        <NA>  \n",
       "..        ...  \n",
       "95       <NA>  \n",
       "96       <NA>  \n",
       "97       <NA>  \n",
       "98       <NA>  \n",
       "99       <NA>  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ランタイム設定（必要なら上書き可）\n",
    "STRUCTURED_SAMPLE_SIZE = 50\n",
    "RANDOM_SEED = 42\n",
    "MODEL = \"gpt-4o-mini\"  # 例。使いたいモデル名に置き換え\n",
    "\n",
    "# メイン関数\n",
    "def run_tiny_structured_classification(records_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - records_df: index がレコードID、columns に 'text' と 'category' を想定\n",
    "    - 返り値: llm_category / llm_reason が追加された DataFrame\n",
    "    \"\"\"\n",
    "    # 必須列チェック\n",
    "    for col in (\"text\", \"category\"):\n",
    "        if col not in records_df.columns:\n",
    "            raise ValueError(f\"records_df に '{col}' 列が必要です。\")\n",
    "\n",
    "    # インデックスを文字列IDに\n",
    "    df = records_df.copy()\n",
    "    if df.index.name is None:\n",
    "        df.index.name = \"id\"\n",
    "    df.index = df.index.astype(str)\n",
    "\n",
    "    # 1) 候補カテゴリ\n",
    "    candidate_categories = sorted(df[\"category\"].dropna().astype(str).unique().tolist())\n",
    "    if not candidate_categories:\n",
    "        raise ValueError(\"candidate_categories が空です。records_df['category'] に値が必要です。\")\n",
    "\n",
    "    # 2) サンプル抽出\n",
    "    n = min(STRUCTURED_SAMPLE_SIZE, len(df))\n",
    "    sample_df = (\n",
    "        df.reset_index(names=\"record_id\")\n",
    "          .sample(n=n, random_state=RANDOM_SEED)\n",
    "          .assign(record_id=lambda d: d[\"record_id\"].astype(str))\n",
    "          .sort_values(\"record_id\", kind=\"stable\")\n",
    "          .loc[:, [\"record_id\", \"text\"]]\n",
    "    )\n",
    "\n",
    "    # 3) JSON ペイロード\n",
    "    prompt_payload = json.dumps(sample_df.to_dict(orient=\"records\"), ensure_ascii=False, indent=2)\n",
    "\n",
    "    # 4) LangChain の structured output（Pydantic をそのまま指定）\n",
    "    #    記事の方法に倣い、with_structured_output() でスキーマを与える\n",
    "    llm = ChatOpenAI(model=MODEL, temperature=0)\n",
    "    structured_llm = llm.with_structured_output(ClassificationBatch)  # ←ここがポイント\n",
    "\n",
    "    system_text = (\n",
    "        \"You are assisting with Japanese idea classification. \"\n",
    "        \"Select exactly one category per record and explain your choice.\"\n",
    "    )\n",
    "\n",
    "    user_parts = [\n",
    "        \"Allowed categories:\\n- \" + \"\\n- \".join(candidate_categories),\n",
    "        (\n",
    "            \"Respond with a `classifications` array ordered by `record_id` \"\n",
    "            \"where each item has `record_id`, `category`, and `reason`. \"\n",
    "            \"Here are the records (JSON list):\"\n",
    "        ),\n",
    "        prompt_payload,\n",
    "    ]\n",
    "    user_text = \"\\n\\n\".join(user_parts)\n",
    "\n",
    "    # LangChain は messages=[...] を dict で渡すより、invoke に単一文字列を渡すのが簡単\n",
    "    # ただしシステム/ユーザーの区別をつけたいので、messages 形式で渡す\n",
    "    result: ClassificationBatch = structured_llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_text},\n",
    "        {\"role\": \"user\", \"content\": user_text},\n",
    "    ])\n",
    "    # ↑ Pydantic にパース済みの `ClassificationBatch` が返る（記事の手法）:contentReference[oaicite:1]{index=1}\n",
    "\n",
    "    # 5) DataFrame に反映\n",
    "    out = df.assign(llm_category=pd.NA, llm_reason=pd.NA).copy()\n",
    "\n",
    "    # ID 整合性チェック\n",
    "    ids_from_model = [c.record_id for c in result.classifications]\n",
    "    not_found = [rid for rid in ids_from_model if rid not in out.index]\n",
    "    if not_found:\n",
    "        raise KeyError(f\"records_df に存在しない record_id が含まれています: {not_found[:5]} ...\")\n",
    "\n",
    "    # 反映\n",
    "    for c in result.classifications:\n",
    "        out.loc[c.record_id, \"llm_category\"] = c.category\n",
    "        out.loc[c.record_id, \"llm_reason\"] = c.reason\n",
    "\n",
    "    return out\n",
    "\n",
    "# ==== 4) 使い方 ====\n",
    "new_df = run_tiny_structured_classification(records_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "002fb054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>アイデアＩＤ</th>\n",
       "      <th>アイデアタイトル</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>llm_category</th>\n",
       "      <th>llm_reason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1236</td>\n",
       "      <td>ホワイトボードマッピング化</td>\n",
       "      <td>全従業員が必ず使用しているホワイトボードに革命を起こします。\\r\\n誰がどこにいて、何をして...</td>\n",
       "      <td>総務</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>営業</td>\n",
       "      <td>業務効率向上のためのホワイトボードの提案で、営業活動に関連する内容だから。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1139</td>\n",
       "      <td>人の想いは永遠に（ドローン空撮・動画作品編集）</td>\n",
       "      <td>代々引き継いできた土地の記録を残したい都市農家の大地主より、敷地全体の航空写真と思い入れのあ...</td>\n",
       "      <td>営業</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>サービス</td>\n",
       "      <td>土地の記録を残すサービス提案で、サービスに関連する内容だから。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>66</td>\n",
       "      <td>謎解きを活用した自律型研修システムの開発</td>\n",
       "      <td>電鉄会社などで流行っている謎解きを使って、受講生の心に残る研修システムを作りませんか？\\r\\...</td>\n",
       "      <td>サービス</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>福利厚生・制度</td>\n",
       "      <td>研修システムの提案で、社員育成に関する福利厚生に関連する内容だから。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1392</td>\n",
       "      <td>シャーメゾンＣＡＦＥ</td>\n",
       "      <td>今までの経験や知識を活かしつつ、いつもとは違う仕事もやってみたい。計画段階よりシャーメゾン物...</td>\n",
       "      <td>新規事業</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>新規事業</td>\n",
       "      <td>CAFEの出店提案で、新たな事業の展開に関する内容だから。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>69</td>\n",
       "      <td>SAKE－積水ハウスのオリジナルノベルティの開発</td>\n",
       "      <td>オリジナルのノベルティとして日本酒を追加してみてはいかがでしょうか。\\r\\n世界的に日本のS...</td>\n",
       "      <td>営業</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>商品開発</td>\n",
       "      <td>日本酒のノベルティ提案で、商品開発に関連する内容だから。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    アイデアＩＤ                  アイデアタイトル  \\\n",
       "id                                     \n",
       "23    1236             ホワイトボードマッピング化   \n",
       "43    1139   人の想いは永遠に（ドローン空撮・動画作品編集）   \n",
       "44      66      謎解きを活用した自律型研修システムの開発   \n",
       "51    1392                シャーメゾンＣＡＦＥ   \n",
       "65      69  SAKE－積水ハウスのオリジナルノベルティの開発   \n",
       "\n",
       "                                                 text category        \\\n",
       "id                                                                     \n",
       "23  全従業員が必ず使用しているホワイトボードに革命を起こします。\\r\\n誰がどこにいて、何をして...       総務  None   \n",
       "43  代々引き継いできた土地の記録を残したい都市農家の大地主より、敷地全体の航空写真と思い入れのあ...       営業  None   \n",
       "44  電鉄会社などで流行っている謎解きを使って、受講生の心に残る研修システムを作りませんか？\\r\\...     サービス  None   \n",
       "51  今までの経験や知識を活かしつつ、いつもとは違う仕事もやってみたい。計画段階よりシャーメゾン物...     新規事業  None   \n",
       "65  オリジナルのノベルティとして日本酒を追加してみてはいかがでしょうか。\\r\\n世界的に日本のS...       営業  None   \n",
       "\n",
       "    category_id llm_category                             llm_reason  \n",
       "id                                                                   \n",
       "23            8           営業  業務効率向上のためのホワイトボードの提案で、営業活動に関連する内容だから。  \n",
       "43            3         サービス        土地の記録を残すサービス提案で、サービスに関連する内容だから。  \n",
       "44            1      福利厚生・制度     研修システムの提案で、社員育成に関する福利厚生に関連する内容だから。  \n",
       "51            4         新規事業          CAFEの出店提案で、新たな事業の展開に関する内容だから。  \n",
       "65            3         商品開発           日本酒のノベルティ提案で、商品開発に関連する内容だから。  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_reason = new_df[\"llm_reason\"].notna() & new_df[\"llm_reason\"].astype(str).str.strip().ne(\"\")\n",
    "filtered = new_df.loc[has_reason].copy()\n",
    "\n",
    "filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cc525e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.to_csv(\"data/filtered_classifications.csv\", index=True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Purpose: Define embedding helpers tailored for instruction-tuned E5 family models.\n",
    "def normalize_for_instruction(text: str, instruction: str = E5_INSTRUCTION) -> str:\n",
    "    \"\"\"Prefix text with the E5 instruction keyword to unlock better multilingual embeddings.\"\"\"\n",
    "    clean = text.strip().replace(\"\\n\", \" \")\n",
    "    return f\"{instruction}{clean}\"\n",
    "\n",
    "\n",
    "def build_embedder(model_name: str = EMBED_MODEL_NAME) -> SentenceTransformer:\n",
    "    \"\"\"Load and return a SentenceTransformer model; default is multilingual-e5-small.\"\"\"\n",
    "    return SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "def embed_texts(\n",
    "    embedder: SentenceTransformer,\n",
    "    texts: Iterable[str],\n",
    "    instruction: str = E5_INSTRUCTION,\n",
    "    batch_size: int = 32,\n",
    "    normalize_embeddings: bool = True,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Convert iterable of texts into normalized embeddings with the provided instruction prefix.\"\"\"\n",
    "    prepared = [normalize_for_instruction(text, instruction) for text in texts]\n",
    "    vectors = embedder.encode(\n",
    "        prepared,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=False,\n",
    "        normalize_embeddings=normalize_embeddings,\n",
    "    )\n",
    "    return np.asarray(vectors, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 15:08:00,613 INFO Use pytorch device_name: cpu\n",
      "2025-11-10 15:08:00,615 INFO Load pretrained SentenceTransformer: stsb-xlm-r-multilingual\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58f6e719b5b4b6a8d8d6d78279d2926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c87daa36504ca0bb0212257fcdd4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129745ddaafd467eb495bc6e2e20be92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cde59512774892aa08cc1ced650ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3c5681a6ba4bc984e544ab5d7f086e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/709 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "2025-11-10 15:08:19,374 WARNING Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4817977e854fba9d3bc4309c35763b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e44b87a32f24830a8c1af7accc80d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/505 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299e1ecc8d6f400d8d3fc66dc0325a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "2025-11-10 15:09:23,276 WARNING Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb91584ae394abc9a1febb7b8e22203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edf445c3a9a407993f6239e1d883a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fd52cd5a4f466fa175cad6eaa9deb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1287, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Purpose: Instantiate the embedder and transform all texts into dense vectors.\n",
    "embedder = build_embedder()\n",
    "text_embeddings = embed_texts(embedder, records_df[\"text\"])\n",
    "text_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1287, 778)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Purpose: Build category-level embeddings and cosine-similarity features to enrich the model input space.\n",
    "def build_category_embeddings(\n",
    "    embedder: SentenceTransformer,\n",
    "    category_texts: Iterable[str],\n",
    "    instruction: str = E5_INSTRUCTION,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Generate normalized embeddings for each category description/name.\"\"\"\n",
    "    prepared = [normalize_for_instruction(text, instruction) for text in category_texts]\n",
    "    return embedder.encode(\n",
    "        prepared,\n",
    "        batch_size=len(prepared),\n",
    "        show_progress_bar=False,\n",
    "        normalize_embeddings=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def concat_similarity_features(\n",
    "    text_vectors: np.ndarray,\n",
    "    category_vectors: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute cosine similarities and append them to the original embeddings.\"\"\"\n",
    "    similarities = text_vectors @ category_vectors.T\n",
    "    return np.hstack([text_vectors, similarities])\n",
    "\n",
    "\n",
    "category_embeddings = build_category_embeddings(embedder, label_encoder.classes_)\n",
    "augmented_embeddings = concat_similarity_features(text_embeddings, category_embeddings)\n",
    "augmented_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Purpose: Create modeling utilities for CV + holdout evaluation on multiple classifiers, including LightGBM & bagging.\n",
    "def build_model_registry(random_state: int = RANDOM_SEED) -> Dict[str, Callable[[], object]]:\n",
    "    \"\"\"Return a set of lazily-initialized sklearn-compatible estimators with consistent preprocessing.\"\"\"\n",
    "\n",
    "    def make_logistic() -> LogisticRegression:\n",
    "        return LogisticRegression(max_iter=4000, random_state=random_state)\n",
    "\n",
    "    def make_bagging_logistic() -> BaggingClassifier:\n",
    "        return BaggingClassifier(\n",
    "            estimator=make_logistic(),\n",
    "            n_estimators=15,\n",
    "            max_samples=0.85,\n",
    "            bootstrap=True,\n",
    "            random_state=random_state,\n",
    "            n_jobs=None,\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"linear_svm\": lambda: Pipeline(\n",
    "            [(\"scaler\", StandardScaler()), (\"clf\", LinearSVC(random_state=random_state))]\n",
    "        ),\n",
    "        \"logistic_regression\": lambda: Pipeline(\n",
    "            [(\"scaler\", StandardScaler()), (\"clf\", make_logistic())]\n",
    "        ),\n",
    "        \"mlp_classifier\": lambda: Pipeline(\n",
    "            [\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\n",
    "                    \"clf\",\n",
    "                    MLPClassifier(\n",
    "                        hidden_layer_sizes=(384,),\n",
    "                        activation=\"relu\",\n",
    "                        max_iter=1500,\n",
    "                        random_state=random_state,\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        \"lightgbm\": lambda: LGBMClassifier(\n",
    "            n_estimators=600,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            reg_lambda=0.1,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1,\n",
    "            verbosity=-1,\n",
    "        ),\n",
    "        \"bagging_log_reg\": lambda: Pipeline(\n",
    "            [(\"scaler\", StandardScaler()), (\"clf\", make_bagging_logistic())]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "def cross_validate_models(\n",
    "    model_builders: Dict[str, Callable[[], object]],\n",
    "    features: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    cv_splits: int = 5,\n",
    "    seed: int = RANDOM_SEED,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Run stratified K-fold cross validation and return accuracy/F1 means and stds per model.\"\"\"\n",
    "    splitter = model_selection.StratifiedKFold(\n",
    "        n_splits=cv_splits,\n",
    "        shuffle=True,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    rows: List[Dict[str, float]] = []\n",
    "    for name, builder in model_builders.items():\n",
    "        estimator = builder()\n",
    "        scores = model_selection.cross_validate(\n",
    "            estimator,\n",
    "            features,\n",
    "            labels,\n",
    "            cv=splitter,\n",
    "            scoring=[\"accuracy\", \"f1_macro\"],\n",
    "            n_jobs=None,\n",
    "        )\n",
    "        rows.append(\n",
    "            {\n",
    "                \"name\": name,\n",
    "                \"cv_accuracy_mean\": scores[\"test_accuracy\"].mean(),\n",
    "                \"cv_accuracy_std\": scores[\"test_accuracy\"].std(),\n",
    "                \"cv_macro_f1_mean\": scores[\"test_f1_macro\"].mean(),\n",
    "                \"cv_macro_f1_std\": scores[\"test_f1_macro\"].std(),\n",
    "            }\n",
    "        )\n",
    "    return (\n",
    "        pd.DataFrame(rows)\n",
    "        .sort_values(\"cv_macro_f1_mean\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def holdout_report_for_model(\n",
    "    model,\n",
    "    features: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    label_names: Iterable[str],\n",
    "    test_size: float = 0.2,\n",
    "    seed: int = RANDOM_SEED,\n",
    ") -> Tuple[Dict[str, float], str]:\n",
    "    \"\"\"Train/validate a single model on a hold-out split and return metrics plus report.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        features,\n",
    "        labels,\n",
    "        test_size=test_size,\n",
    "        stratify=labels,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    metrics_dict = {\n",
    "        \"accuracy\": metrics.accuracy_score(y_test, preds),\n",
    "        \"macro_f1\": metrics.f1_score(y_test, preds, average=\"macro\"),\n",
    "    }\n",
    "    report = metrics.classification_report(y_test, preds, target_names=list(label_names))\n",
    "    return metrics_dict, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>cv_accuracy_mean</th>\n",
       "      <th>cv_accuracy_std</th>\n",
       "      <th>cv_macro_f1_mean</th>\n",
       "      <th>cv_macro_f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp_classifier</td>\n",
       "      <td>0.522954</td>\n",
       "      <td>0.018226</td>\n",
       "      <td>0.441220</td>\n",
       "      <td>0.026654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bagging_log_reg</td>\n",
       "      <td>0.514394</td>\n",
       "      <td>0.031474</td>\n",
       "      <td>0.428015</td>\n",
       "      <td>0.042082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.485651</td>\n",
       "      <td>0.025082</td>\n",
       "      <td>0.404763</td>\n",
       "      <td>0.035221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.512065</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.403454</td>\n",
       "      <td>0.014276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linear_svm</td>\n",
       "      <td>0.439010</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>0.358406</td>\n",
       "      <td>0.024228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  cv_accuracy_mean  cv_accuracy_std  cv_macro_f1_mean  \\\n",
       "0       mlp_classifier          0.522954         0.018226          0.441220   \n",
       "1      bagging_log_reg          0.514394         0.031474          0.428015   \n",
       "2  logistic_regression          0.485651         0.025082          0.404763   \n",
       "3             lightgbm          0.512065         0.014932          0.403454   \n",
       "4           linear_svm          0.439010         0.024648          0.358406   \n",
       "\n",
       "   cv_macro_f1_std  \n",
       "0         0.026654  \n",
       "1         0.042082  \n",
       "2         0.035221  \n",
       "3         0.014276  \n",
       "4         0.024228  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Purpose: Execute cross validation across all models and inspect their ranking.\n",
    "model_registry = build_model_registry()\n",
    "cv_results = cross_validate_models(model_registry, augmented_embeddings, records_df[\"category_id\"].values)\n",
    "cv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'bagging_log_reg',\n",
       "  'accuracy': 0.5077519379844961,\n",
       "  'macro_f1': 0.42477571126918273,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n         ESG       0.56      0.70      0.62        20\\n        サービス       0.35      0.32      0.33        22\\n        商品開発       0.50      0.38      0.43        13\\n          営業       0.31      0.35      0.33        26\\n        新規事業       0.25      0.29      0.27        14\\n          施工       0.56      0.64      0.60        36\\n          生産       0.00      0.00      0.00         5\\n     福利厚生・制度       0.68      0.61      0.64        59\\n          総務       0.55      0.55      0.55        38\\n          設計       0.46      0.48      0.47        25\\n\\n    accuracy                           0.51       258\\n   macro avg       0.42      0.43      0.42       258\\nweighted avg       0.50      0.51      0.50       258\\n'},\n",
       " {'name': 'logistic_regression',\n",
       "  'accuracy': 0.46511627906976744,\n",
       "  'macro_f1': 0.4059759313380746,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n         ESG       0.48      0.60      0.53        20\\n        サービス       0.26      0.23      0.24        22\\n        商品開発       0.38      0.38      0.38        13\\n          営業       0.39      0.46      0.42        26\\n        新規事業       0.18      0.21      0.19        14\\n          施工       0.55      0.58      0.57        36\\n          生産       0.33      0.20      0.25         5\\n     福利厚生・制度       0.67      0.61      0.64        59\\n          総務       0.48      0.34      0.40        38\\n          設計       0.39      0.48      0.43        25\\n\\n    accuracy                           0.47       258\\n   macro avg       0.41      0.41      0.41       258\\nweighted avg       0.47      0.47      0.46       258\\n'},\n",
       " {'name': 'lightgbm',\n",
       "  'accuracy': 0.47674418604651164,\n",
       "  'macro_f1': 0.4098597395318707,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n         ESG       0.50      0.50      0.50        20\\n        サービス       0.41      0.32      0.36        22\\n        商品開発       0.31      0.31      0.31        13\\n          営業       0.21      0.15      0.18        26\\n        新規事業       0.33      0.29      0.31        14\\n          施工       0.55      0.64      0.59        36\\n          生産       0.50      0.20      0.29         5\\n     福利厚生・制度       0.60      0.64      0.62        59\\n          総務       0.51      0.53      0.52        38\\n          設計       0.39      0.48      0.43        25\\n\\n    accuracy                           0.48       258\\n   macro avg       0.43      0.41      0.41       258\\nweighted avg       0.47      0.48      0.47       258\\n'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Purpose: Evaluate the top-2 CV models (logistic + bagging) and LightGBM on a hold-out split for sanity check.\n",
    "ranked_models = cv_results[\"name\"].tolist()\n",
    "selected = [name for name in ranked_models if name in {\"logistic_regression\", \"bagging_log_reg\", \"lightgbm\"}]\n",
    "reports: List[Dict[str, object]] = []\n",
    "for name in selected:\n",
    "    model = model_registry[name]()\n",
    "    metrics_dict, report = holdout_report_for_model(\n",
    "        model,\n",
    "        augmented_embeddings,\n",
    "        records_df[\"category_id\"].values,\n",
    "        label_encoder.classes_,\n",
    "    )\n",
    "    reports.append({\"name\": name, **metrics_dict, \"report\": report})\n",
    "reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 16:12:51,630] A new study created in memory with name: no-name-c283deb0-6c3d-4692-a01a-018e4b97c22f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 16:12:55,093] Trial 0 finished with value: 0.41567665942826454 and parameters: {'C': 0.13292918943162169, 'fit_intercept': True, 'class_weight': None, 'tol': 2.9375384576328295e-05}. Best is trial 0 with value: 0.41567665942826454.\n",
      "[I 2025-11-10 16:12:55,625] Trial 1 finished with value: 0.4352056744209397 and parameters: {'C': 0.014936568554617643, 'fit_intercept': True, 'class_weight': None, 'tol': 0.008123245085588688}. Best is trial 1 with value: 0.4352056744209397.\n",
      "[I 2025-11-10 16:12:56,731] Trial 2 finished with value: 0.3878548994418309 and parameters: {'C': 3.142880890840109, 'fit_intercept': True, 'class_weight': 'balanced', 'tol': 0.00037520558551242813}. Best is trial 1 with value: 0.4352056744209397.\n",
      "[I 2025-11-10 16:12:58,011] Trial 3 finished with value: 0.39672971649782124 and parameters: {'C': 0.19762189340280073, 'fit_intercept': False, 'class_weight': 'balanced', 'tol': 0.00012562773503807024}. Best is trial 1 with value: 0.4352056744209397.\n",
      "[I 2025-11-10 16:13:01,452] Trial 4 finished with value: 0.40675377592253364 and parameters: {'C': 0.23345864076016243, 'fit_intercept': True, 'class_weight': 'balanced', 'tol': 1.3783237455007187e-05}. Best is trial 1 with value: 0.4352056744209397.\n",
      "[I 2025-11-10 16:13:01,986] Trial 5 finished with value: 0.39447729663054004 and parameters: {'C': 0.6647135865318028, 'fit_intercept': True, 'class_weight': 'balanced', 'tol': 0.002661901888489057}. Best is trial 1 with value: 0.4352056744209397.\n",
      "[I 2025-11-10 16:13:02,916] Trial 6 finished with value: 0.4140393437635157 and parameters: {'C': 0.08200518402245831, 'fit_intercept': False, 'class_weight': None, 'tol': 0.0003058656666978527}. Best is trial 1 with value: 0.4352056744209397.\n",
      "[I 2025-11-10 16:13:04,393] Trial 7 finished with value: 0.4367306474576531 and parameters: {'C': 0.012681352169084602, 'fit_intercept': True, 'class_weight': None, 'tol': 0.00036324869566766035}. Best is trial 7 with value: 0.4367306474576531.\n",
      "[I 2025-11-10 16:13:04,809] Trial 8 finished with value: 0.40148805702759305 and parameters: {'C': 0.43664735929796333, 'fit_intercept': False, 'class_weight': 'balanced', 'tol': 0.004835952776465951}. Best is trial 7 with value: 0.4367306474576531.\n",
      "[I 2025-11-10 16:13:07,137] Trial 9 finished with value: 0.40713689397223857 and parameters: {'C': 0.6218704727769077, 'fit_intercept': True, 'class_weight': None, 'tol': 9.46217535646148e-05}. Best is trial 7 with value: 0.4367306474576531.\n",
      "[I 2025-11-10 16:13:07,507] Trial 10 finished with value: 0.43147968797038133 and parameters: {'C': 0.011522369166125162, 'fit_intercept': False, 'class_weight': None, 'tol': 0.001032301585700146}. Best is trial 7 with value: 0.4367306474576531.\n",
      "[I 2025-11-10 16:13:08,011] Trial 11 finished with value: 0.441221876237626 and parameters: {'C': 0.011055580224171557, 'fit_intercept': True, 'class_weight': None, 'tol': 0.008567052742936003}. Best is trial 11 with value: 0.441221876237626.\n",
      "[I 2025-11-10 16:13:09,177] Trial 12 finished with value: 0.425053282130097 and parameters: {'C': 0.03800285707546566, 'fit_intercept': True, 'class_weight': None, 'tol': 0.0012344334884639753}. Best is trial 11 with value: 0.441221876237626.\n",
      "[I 2025-11-10 16:13:10,378] Trial 13 finished with value: 0.42566507165250267 and parameters: {'C': 0.03361349978257709, 'fit_intercept': True, 'class_weight': None, 'tol': 0.0014193925068113112}. Best is trial 11 with value: 0.441221876237626.\n",
      "[I 2025-11-10 16:13:11,819] Trial 14 finished with value: 0.425839372715158 and parameters: {'C': 0.03384605403323476, 'fit_intercept': True, 'class_weight': None, 'tol': 0.00045297967956856575}. Best is trial 11 with value: 0.441221876237626.\n",
      "[I 2025-11-10 16:13:13,553] Trial 15 finished with value: 0.3956871024453768 and parameters: {'C': 5.441895147012023, 'fit_intercept': True, 'class_weight': None, 'tol': 6.65970389393196e-05}. Best is trial 11 with value: 0.441221876237626.\n",
      "[I 2025-11-10 16:13:14,058] Trial 16 finished with value: 0.4365432471788046 and parameters: {'C': 0.011092010681502189, 'fit_intercept': True, 'class_weight': None, 'tol': 0.009728583151931043}. Best is trial 11 with value: 0.441221876237626.\n",
      "[I 2025-11-10 16:13:15,150] Trial 17 finished with value: 0.41848139913676424 and parameters: {'C': 0.06988896950734964, 'fit_intercept': True, 'class_weight': None, 'tol': 0.003173500150935368}. Best is trial 11 with value: 0.441221876237626.\n",
      "[I 2025-11-10 16:13:16,075] Trial 18 finished with value: 0.4281181443931484 and parameters: {'C': 0.024953825793029828, 'fit_intercept': False, 'class_weight': None, 'tol': 0.00024222252021885852}. Best is trial 11 with value: 0.441221876237626.\n",
      "[I 2025-11-10 16:13:17,010] Trial 19 finished with value: 0.39708313616853885 and parameters: {'C': 1.5470504932079145, 'fit_intercept': True, 'class_weight': None, 'tol': 0.0006945421991171685}. Best is trial 11 with value: 0.441221876237626.\n",
      "[I 2025-11-10 16:13:20,953] Trial 20 finished with value: 0.4170774099278753 and parameters: {'C': 0.06368569562079539, 'fit_intercept': True, 'class_weight': None, 'tol': 3.511003200180574e-05}. Best is trial 11 with value: 0.441221876237626.\n",
      "[I 2025-11-10 16:13:21,626] Trial 21 finished with value: 0.4380850930215997 and parameters: {'C': 0.012981802005488704, 'fit_intercept': True, 'class_weight': None, 'tol': 0.008087411777442793}. Best is trial 11 with value: 0.441221876237626.\n",
      "[I 2025-11-10 16:13:22,339] Trial 22 finished with value: 0.4301072157069334 and parameters: {'C': 0.019450915266112097, 'fit_intercept': True, 'class_weight': None, 'tol': 0.004478032730332659}. Best is trial 11 with value: 0.441221876237626.\n",
      "[I 2025-11-10 16:13:23,391] Trial 23 finished with value: 0.4336001590009557 and parameters: {'C': 0.010178400578607338, 'fit_intercept': True, 'class_weight': None, 'tol': 0.0021256851521634494}. Best is trial 11 with value: 0.441221876237626.\n",
      "[I 2025-11-10 16:13:24,037] Trial 24 finished with value: 0.42502380559885305 and parameters: {'C': 0.020122927722558442, 'fit_intercept': True, 'class_weight': None, 'tol': 0.006517856409942496}. Best is trial 11 with value: 0.441221876237626.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.441221876237626,\n",
       " {'C': 0.011055580224171557,\n",
       "  'fit_intercept': True,\n",
       "  'class_weight': None,\n",
       "  'tol': 0.008567052742936003})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Purpose: Use Optuna to tune the Logistic Regression pipeline and push macro-F1 higher via CV.\n",
    "def tune_logistic_with_optuna(\n",
    "    features: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    n_trials: int = 25,\n",
    "    seed: int = RANDOM_SEED,\n",
    ") -> optuna.Study:\n",
    "    \"\"\"Optimize logistic regression hyperparameters with Optuna and return the study.\"\"\"\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        C = trial.suggest_float(\"C\", 1e-2, 10.0, log=True)\n",
    "        fit_intercept = trial.suggest_categorical(\"fit_intercept\", [True, False])\n",
    "        class_weight = trial.suggest_categorical(\"class_weight\", [None, \"balanced\"])\n",
    "        tol = trial.suggest_float(\"tol\", 1e-5, 1e-2, log=True)\n",
    "        model = Pipeline(\n",
    "            [\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\n",
    "                    \"clf\",\n",
    "                    LogisticRegression(\n",
    "                        C=C,\n",
    "                        fit_intercept=fit_intercept,\n",
    "                        class_weight=class_weight,\n",
    "                        tol=tol,\n",
    "                        max_iter=5000,\n",
    "                        random_state=seed,\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        splitter = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        scores = model_selection.cross_val_score(\n",
    "            model,\n",
    "            features,\n",
    "            labels,\n",
    "            cv=splitter,\n",
    "            scoring=\"f1_macro\",\n",
    "            n_jobs=None,\n",
    "        )\n",
    "        return float(scores.mean())\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=optuna.samplers.TPESampler(seed=seed),\n",
    "    )\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study\n",
    "\n",
    "\n",
    "log_reg_study = tune_logistic_with_optuna(augmented_embeddings, records_df[\"category_id\"].values)\n",
    "log_reg_study.best_value, log_reg_study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 16:15:29,847] A new study created in memory with name: no-name-b09df28b-6ede-4441-b553-cd51f606fe2b\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:16:00,713] Trial 0 finished with value: 0.3965001586695598 and parameters: {'num_leaves': 29, 'max_depth': 12, 'learning_rate': 0.08960785365368121, 'feature_fraction': 0.8394633936788146, 'bagging_fraction': 0.6624074561769746, 'bagging_freq': 2, 'min_child_samples': 6, 'lambda_l1': 2.9154431891537547, 'lambda_l2': 0.2537815508265665}. Best is trial 0 with value: 0.3965001586695598.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:16:52,977] Trial 1 finished with value: 0.39253566253902605 and parameters: {'num_leaves': 48, 'max_depth': 3, 'learning_rate': 0.18276027831785724, 'feature_fraction': 0.9329770563201687, 'bagging_fraction': 0.6849356442713105, 'bagging_freq': 2, 'min_child_samples': 9, 'lambda_l1': 0.016480446427978974, 'lambda_l2': 0.12561043700013558}. Best is trial 0 with value: 0.3965001586695598.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:17:35,240] Trial 2 finished with value: 0.41888688623608666 and parameters: {'num_leaves': 32, 'max_depth': 5, 'learning_rate': 0.06252287916406217, 'feature_fraction': 0.6557975442608167, 'bagging_fraction': 0.7168578594140873, 'bagging_freq': 3, 'min_child_samples': 16, 'lambda_l1': 1.382623217936987, 'lambda_l2': 0.006290644294586149}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:19:10,494] Trial 3 finished with value: 0.3817918257831912 and parameters: {'num_leaves': 37, 'max_depth': 8, 'learning_rate': 0.011492999300221412, 'feature_fraction': 0.8430179407605753, 'bagging_fraction': 0.6682096494749166, 'bagging_freq': 1, 'min_child_samples': 29, 'lambda_l1': 7.2866537374910445, 'lambda_l2': 1.7123375973163988}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:20:06,856] Trial 4 finished with value: 0.4064434367278545 and parameters: {'num_leaves': 25, 'max_depth': 3, 'learning_rate': 0.07766184280392888, 'feature_fraction': 0.7760609974958406, 'bagging_fraction': 0.6488152939379115, 'bagging_freq': 4, 'min_child_samples': 5, 'lambda_l1': 4.337920697490942, 'lambda_l2': 0.010842262717330166}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:21:12,030] Trial 5 finished with value: 0.38864838609164004 and parameters: {'num_leaves': 45, 'max_depth': 6, 'learning_rate': 0.04749239763680407, 'feature_fraction': 0.8186841117373118, 'bagging_fraction': 0.6739417822102108, 'bagging_freq': 7, 'min_child_samples': 25, 'lambda_l1': 5.727904470799623, 'lambda_l2': 3.7958531426706403}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:25:45,922] Trial 6 finished with value: 0.40671112155536804 and parameters: {'num_leaves': 42, 'max_depth': 12, 'learning_rate': 0.01303561122512888, 'feature_fraction': 0.6783931449676581, 'bagging_fraction': 0.6180909155642152, 'bagging_freq': 3, 'min_child_samples': 15, 'lambda_l1': 0.01217295809836997, 'lambda_l2': 2.0651425578959257}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:26:55,403] Trial 7 finished with value: 0.4107395362035005 and parameters: {'num_leaves': 28, 'max_depth': 5, 'learning_rate': 0.05082341959721458, 'feature_fraction': 0.6563696899899051, 'bagging_fraction': 0.9208787923016158, 'bagging_freq': 1, 'min_child_samples': 30, 'lambda_l1': 1.2273800987852967, 'lambda_l2': 0.0062353771356731605}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:31:17,198] Trial 8 finished with value: 0.40091954072793257 and parameters: {'num_leaves': 8, 'max_depth': 11, 'learning_rate': 0.08310795711416077, 'feature_fraction': 0.8916028672163949, 'bagging_fraction': 0.9085081386743783, 'bagging_freq': 1, 'min_child_samples': 14, 'lambda_l1': 0.0029072088906598446, 'lambda_l2': 2.8340904295147746}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:33:28,659] Trial 9 finished with value: 0.41115217409337196 and parameters: {'num_leaves': 43, 'max_depth': 6, 'learning_rate': 0.012097379927033842, 'feature_fraction': 0.7243929286862649, 'bagging_fraction': 0.7300733288106989, 'bagging_freq': 6, 'min_child_samples': 21, 'lambda_l1': 3.53875886477924, 'lambda_l2': 0.0774211647399625}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:35:48,832] Trial 10 finished with value: 0.4122884419029266 and parameters: {'num_leaves': 61, 'max_depth': 9, 'learning_rate': 0.025137344588454093, 'feature_fraction': 0.6071847502459279, 'bagging_fraction': 0.8010124870699186, 'bagging_freq': 5, 'min_child_samples': 20, 'lambda_l1': 0.313569713135636, 'lambda_l2': 0.0014442093185114905}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:38:32,824] Trial 11 finished with value: 0.40240235545603487 and parameters: {'num_leaves': 64, 'max_depth': 9, 'learning_rate': 0.023374412206397632, 'feature_fraction': 0.6097132653988919, 'bagging_fraction': 0.8142497056141959, 'bagging_freq': 5, 'min_child_samples': 20, 'lambda_l1': 0.2916399115521992, 'lambda_l2': 0.0010440015084463524}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:41:14,565] Trial 12 finished with value: 0.4171591271701187 and parameters: {'num_leaves': 61, 'max_depth': 9, 'learning_rate': 0.024917659239788312, 'feature_fraction': 0.6028229750906781, 'bagging_fraction': 0.7874820875551369, 'bagging_freq': 4, 'min_child_samples': 13, 'lambda_l1': 0.23604599745298555, 'lambda_l2': 0.001032664784302312}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:45:19,504] Trial 13 finished with value: 0.40980402003620914 and parameters: {'num_leaves': 15, 'max_depth': 5, 'learning_rate': 0.027091877549425217, 'feature_fraction': 0.9997449754566203, 'bagging_fraction': 0.7530856951557253, 'bagging_freq': 4, 'min_child_samples': 11, 'lambda_l1': 0.09735125945191662, 'lambda_l2': 0.007868553528824863}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:47:21,431] Trial 14 finished with value: 0.39866224907883474 and parameters: {'num_leaves': 55, 'max_depth': 10, 'learning_rate': 0.03384936402995744, 'feature_fraction': 0.7251749693579276, 'bagging_fraction': 0.852433737415586, 'bagging_freq': 3, 'min_child_samples': 15, 'lambda_l1': 0.5709831496754426, 'lambda_l2': 0.023285474925771647}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:51:59,826] Trial 15 finished with value: 0.4114082281437648 and parameters: {'num_leaves': 53, 'max_depth': 8, 'learning_rate': 0.018175204454443285, 'feature_fraction': 0.6616960084117212, 'bagging_fraction': 0.7413448867665955, 'bagging_freq': 4, 'min_child_samples': 11, 'lambda_l1': 0.09467228738953766, 'lambda_l2': 0.002619003241784863}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:53:15,597] Trial 16 finished with value: 0.39252458540464874 and parameters: {'num_leaves': 20, 'max_depth': 7, 'learning_rate': 0.14489040687629332, 'feature_fraction': 0.7270951307087735, 'bagging_fraction': 0.8642396983313831, 'bagging_freq': 3, 'min_child_samples': 17, 'lambda_l1': 0.0358985394248392, 'lambda_l2': 0.030211870540414878}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:54:21,654] Trial 17 finished with value: 0.39864646105246393 and parameters: {'num_leaves': 36, 'max_depth': 4, 'learning_rate': 0.0597578629151316, 'feature_fraction': 0.6429198325989578, 'bagging_fraction': 0.769817434569042, 'bagging_freq': 5, 'min_child_samples': 24, 'lambda_l1': 1.029118270299884, 'lambda_l2': 0.003360265256173142}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:56:31,655] Trial 18 finished with value: 0.40689814482992004 and parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.03556132737877548, 'feature_fraction': 0.7730982444721965, 'bagging_fraction': 0.7080522498103962, 'bagging_freq': 2, 'min_child_samples': 11, 'lambda_l1': 0.184294091558854, 'lambda_l2': 0.003530918860812066}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 16:57:08,116] Trial 19 finished with value: 0.3864539915162989 and parameters: {'num_leaves': 57, 'max_depth': 10, 'learning_rate': 0.1154348322596743, 'feature_fraction': 0.699520845917618, 'bagging_fraction': 0.9521173507108853, 'bagging_freq': 6, 'min_child_samples': 17, 'lambda_l1': 1.3252318495660258, 'lambda_l2': 0.02374654960736184}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 17:02:06,380] Trial 20 finished with value: 0.4013631007639131 and parameters: {'num_leaves': 50, 'max_depth': 5, 'learning_rate': 0.01720382564734656, 'feature_fraction': 0.6008286183012101, 'bagging_fraction': 0.9934963658888418, 'bagging_freq': 3, 'min_child_samples': 8, 'lambda_l1': 0.0011129709953152695, 'lambda_l2': 0.7359974431492604}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 17:03:15,149] Trial 21 finished with value: 0.40658179056501786 and parameters: {'num_leaves': 57, 'max_depth': 9, 'learning_rate': 0.03461221280789989, 'feature_fraction': 0.6278562435244938, 'bagging_fraction': 0.79809676050432, 'bagging_freq': 5, 'min_child_samples': 20, 'lambda_l1': 0.37309972091256793, 'lambda_l2': 0.0010504101727747007}. Best is trial 2 with value: 0.41888688623608666.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 17:05:04,276] Trial 22 finished with value: 0.4220133057192686 and parameters: {'num_leaves': 64, 'max_depth': 9, 'learning_rate': 0.023023881732257948, 'feature_fraction': 0.6312583301950802, 'bagging_fraction': 0.7932107758827048, 'bagging_freq': 4, 'min_child_samples': 23, 'lambda_l1': 0.15369004781182277, 'lambda_l2': 0.0017872862735480418}. Best is trial 22 with value: 0.4220133057192686.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 17:08:11,023] Trial 23 finished with value: 0.406904656810692 and parameters: {'num_leaves': 40, 'max_depth': 10, 'learning_rate': 0.01877843418150141, 'feature_fraction': 0.6677535015318947, 'bagging_fraction': 0.8433356075000104, 'bagging_freq': 4, 'min_child_samples': 23, 'lambda_l1': 0.032627305144506305, 'lambda_l2': 0.002560414661680296}. Best is trial 22 with value: 0.4220133057192686.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 17:09:03,244] Trial 24 finished with value: 0.40459608794383806 and parameters: {'num_leaves': 63, 'max_depth': 8, 'learning_rate': 0.06714703561136742, 'feature_fraction': 0.6867116350836747, 'bagging_fraction': 0.7739182262229127, 'bagging_freq': 4, 'min_child_samples': 27, 'lambda_l1': 0.160256479475348, 'lambda_l2': 0.011473217006552437}. Best is trial 22 with value: 0.4220133057192686.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 17:10:52,513] Trial 25 finished with value: 0.41538453077763504 and parameters: {'num_leaves': 59, 'max_depth': 11, 'learning_rate': 0.04010031392753446, 'feature_fraction': 0.6350787452654303, 'bagging_fraction': 0.7082511538557176, 'bagging_freq': 3, 'min_child_samples': 13, 'lambda_l1': 0.04766916451540558, 'lambda_l2': 0.005543990814569893}. Best is trial 22 with value: 0.4220133057192686.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 17:12:37,112] Trial 26 finished with value: 0.40810200071384173 and parameters: {'num_leaves': 51, 'max_depth': 6, 'learning_rate': 0.025806298723140653, 'feature_fraction': 0.7433734606338473, 'bagging_fraction': 0.8280501623725096, 'bagging_freq': 6, 'min_child_samples': 18, 'lambda_l1': 0.7846519311661241, 'lambda_l2': 0.0018952164485693279}. Best is trial 22 with value: 0.4220133057192686.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 17:14:06,340] Trial 27 finished with value: 0.4137446252609992 and parameters: {'num_leaves': 32, 'max_depth': 7, 'learning_rate': 0.014828523149411577, 'feature_fraction': 0.705424041720412, 'bagging_fraction': 0.8912101550266425, 'bagging_freq': 2, 'min_child_samples': 22, 'lambda_l1': 2.0489741958885808, 'lambda_l2': 0.054835806376883275}. Best is trial 22 with value: 0.4220133057192686.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 17:15:35,443] Trial 28 finished with value: 0.4194140686950883 and parameters: {'num_leaves': 23, 'max_depth': 9, 'learning_rate': 0.022504064729628084, 'feature_fraction': 0.6292200607795252, 'bagging_fraction': 0.7809545228586025, 'bagging_freq': 4, 'min_child_samples': 26, 'lambda_l1': 0.4246478065399557, 'lambda_l2': 0.01525886262695486}. Best is trial 22 with value: 0.4220133057192686.\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\fujita096\\PJ\\TextClassificationSuite\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-11-10 17:16:05,396] Trial 29 finished with value: 0.41609688341626816 and parameters: {'num_leaves': 22, 'max_depth': 11, 'learning_rate': 0.10545252623456705, 'feature_fraction': 0.7647571188074668, 'bagging_fraction': 0.7179826781707788, 'bagging_freq': 3, 'min_child_samples': 26, 'lambda_l1': 2.287461665842602, 'lambda_l2': 0.25174720585057053}. Best is trial 22 with value: 0.4220133057192686.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4220133057192686,\n",
       " {'num_leaves': 64,\n",
       "  'max_depth': 9,\n",
       "  'learning_rate': 0.023023881732257948,\n",
       "  'feature_fraction': 0.6312583301950802,\n",
       "  'bagging_fraction': 0.7932107758827048,\n",
       "  'bagging_freq': 4,\n",
       "  'min_child_samples': 23,\n",
       "  'lambda_l1': 0.15369004781182277,\n",
       "  'lambda_l2': 0.0017872862735480418})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Purpose: Tune LightGBM hyperparameters with Optuna to explore boosted-tree capacity.\n",
    "def tune_lightgbm_with_optuna(\n",
    "    features: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    n_trials: int = 30,\n",
    "    seed: int = RANDOM_SEED,\n",
    ") -> optuna.Study:\n",
    "    \"\"\"Optimize LightGBM hyperparameters using Optuna on macro-F1.\"\"\"\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        params = {\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 64),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "            \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "            \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "            \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 30),\n",
    "            \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-3, 10.0, log=True),\n",
    "            \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-3, 10.0, log=True),\n",
    "        }\n",
    "        model = LGBMClassifier(\n",
    "            n_estimators=600,\n",
    "            subsample=params.pop(\"bagging_fraction\"),\n",
    "            subsample_freq=params.pop(\"bagging_freq\"),\n",
    "            colsample_bytree=params.pop(\"feature_fraction\"),\n",
    "            random_state=seed,\n",
    "            n_jobs=-1,\n",
    "            verbosity=-1,\n",
    "            **params,\n",
    "        )\n",
    "        splitter = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        scores = model_selection.cross_val_score(\n",
    "            model,\n",
    "            features,\n",
    "            labels,\n",
    "            cv=splitter,\n",
    "            scoring=\"f1_macro\",\n",
    "            n_jobs=None,\n",
    "        )\n",
    "        return float(scores.mean())\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=optuna.samplers.TPESampler(seed=seed),\n",
    "    )\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study\n",
    "\n",
    "\n",
    "lightgbm_study = tune_lightgbm_with_optuna(augmented_embeddings, records_df[\"category_id\"].values)\n",
    "lightgbm_study.best_value, lightgbm_study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lightgbm_study' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m VotingClassifier(\n\u001b[32m     67\u001b[39m         estimators=[(\u001b[33m\"\u001b[39m\u001b[33mlogreg\u001b[39m\u001b[33m\"\u001b[39m, log_reg), (\u001b[33m\"\u001b[39m\u001b[33mlgbm\u001b[39m\u001b[33m\"\u001b[39m, lgbm)],\n\u001b[32m     68\u001b[39m         voting=\u001b[33m\"\u001b[39m\u001b[33msoft\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     69\u001b[39m         weights=[\u001b[32m0.6\u001b[39m, \u001b[32m0.4\u001b[39m],\n\u001b[32m     70\u001b[39m         n_jobs=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     71\u001b[39m     )\n\u001b[32m     74\u001b[39m tuned_log_reg = build_tuned_logistic(log_reg_study.best_params)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m tuned_lgbm = build_tuned_lightgbm(\u001b[43mlightgbm_study\u001b[49m.best_params)\n\u001b[32m     76\u001b[39m stacking_model = build_stacking_ensemble(tuned_log_reg, tuned_lgbm)\n\u001b[32m     77\u001b[39m voting_model = build_voting_ensemble(tuned_log_reg, tuned_lgbm)\n",
      "\u001b[31mNameError\u001b[39m: name 'lightgbm_study' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Purpose: Build stacking/voting ensembles from the Optuna-tuned base models (non-bagging) and evaluate them.\n",
    "def build_tuned_logistic(best_params: Dict[str, object], seed: int = RANDOM_SEED) -> Pipeline:\n",
    "    \"\"\"Instantiate a StandardScaler+LogReg pipeline using Optuna-best hyperparameters.\"\"\"\n",
    "    params = best_params.copy()\n",
    "    return Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\n",
    "                \"clf\",\n",
    "                LogisticRegression(\n",
    "                    C=params.get(\"C\", 1.0),\n",
    "                    fit_intercept=params.get(\"fit_intercept\", True),\n",
    "                    class_weight=params.get(\"class_weight\"),\n",
    "                    tol=params.get(\"tol\", 1e-4),\n",
    "                    max_iter=5000,\n",
    "                    random_state=seed,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def build_tuned_lightgbm(best_params: Dict[str, object], seed: int = RANDOM_SEED) -> LGBMClassifier:\n",
    "    \"\"\"Instantiate a LightGBM classifier with Optuna-best hyperparameters.\"\"\"\n",
    "    params = best_params.copy()\n",
    "    feature_fraction = params.pop(\"feature_fraction\", 0.9)\n",
    "    bagging_fraction = params.pop(\"bagging_fraction\", 0.9)\n",
    "    bagging_freq = params.pop(\"bagging_freq\", 1)\n",
    "    return LGBMClassifier(\n",
    "        n_estimators=600,\n",
    "        subsample=bagging_fraction,\n",
    "        subsample_freq=bagging_freq,\n",
    "        colsample_bytree=feature_fraction,\n",
    "        random_state=seed,\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1,\n",
    "        **params,\n",
    "    )\n",
    "\n",
    "\n",
    "def build_stacking_ensemble(\n",
    "    log_reg: Pipeline,\n",
    "    lgbm: LGBMClassifier,\n",
    "    seed: int = RANDOM_SEED,\n",
    ") -> StackingClassifier:\n",
    "    \"\"\"Create a stacking classifier that blends tuned LogReg and LightGBM.\"\"\"\n",
    "    estimators = [\n",
    "        (\"logreg\", log_reg),\n",
    "        (\"lgbm\", lgbm),\n",
    "    ]\n",
    "    final_estimator = LogisticRegression(max_iter=4000, random_state=seed)\n",
    "    return StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=final_estimator,\n",
    "        stack_method=\"auto\",\n",
    "        passthrough=False,\n",
    "        n_jobs=None,\n",
    "    )\n",
    "\n",
    "\n",
    "def build_voting_ensemble(\n",
    "    log_reg: Pipeline,\n",
    "    lgbm: LGBMClassifier,\n",
    ") -> VotingClassifier:\n",
    "    \"\"\"Return a soft-voting ensemble combining tuned LogReg and LightGBM.\"\"\"\n",
    "    return VotingClassifier(\n",
    "        estimators=[(\"logreg\", log_reg), (\"lgbm\", lgbm)],\n",
    "        voting=\"soft\",\n",
    "        weights=[0.6, 0.4],\n",
    "        n_jobs=None,\n",
    "    )\n",
    "\n",
    "\n",
    "tuned_log_reg = build_tuned_logistic(log_reg_study.best_params)\n",
    "tuned_lgbm = build_tuned_lightgbm(lightgbm_study.best_params)\n",
    "stacking_model = build_stacking_ensemble(tuned_log_reg, tuned_lgbm)\n",
    "voting_model = build_voting_ensemble(tuned_log_reg, tuned_lgbm)\n",
    "stacking_metrics, stacking_report = holdout_report_for_model(\n",
    "    stacking_model,\n",
    "    augmented_embeddings,\n",
    "    records_df[\"category_id\"].values,\n",
    "    label_encoder.classes_,\n",
    ")\n",
    "voting_metrics, voting_report = holdout_report_for_model(\n",
    "    voting_model,\n",
    "    augmented_embeddings,\n",
    "    records_df[\"category_id\"].values,\n",
    "    label_encoder.classes_,\n",
    ")\n",
    "stacking_metrics, voting_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Purpose: Display the Optuna-ensemble classification reports for qualitative inspection.\n",
    "print(\"=== Stacking ensemble report ===\")\n",
    "print(stacking_report)\n",
    "print(\"=== Voting ensemble report ===\")\n",
    "print(voting_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Purpose: Fit the tuned logistic model on all data to compute per-sample confidence scores and flag low-confidence predictions.\n",
    "def compute_confidence_table(\n",
    "    model: Pipeline,\n",
    "    features: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    label_names: Iterable[str],\n",
    "    threshold: float = 0.8,\n",
    ") -> Tuple[pd.DataFrame, Pipeline]:\n",
    "    \"\"\"Return a DataFrame with predictions, confidences, and a low-confidence flag.\"\"\"\n",
    "    fitted = model.fit(features, labels)\n",
    "    probs = fitted.predict_proba(features)\n",
    "    pred_ids = probs.argmax(axis=1)\n",
    "    confidence = probs.max(axis=1)\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": records_df[\"id\"],\n",
    "            \"text\": records_df[\"text\"],\n",
    "            \"true_label\": records_df[\"category_label\"],\n",
    "            \"pred_label\": [label_names[idx] for idx in pred_ids],\n",
    "            \"pred_label_id\": pred_ids,\n",
    "            \"confidence\": confidence,\n",
    "        }\n",
    "    )\n",
    "    df[\"low_confidence\"] = df[\"confidence\"] < threshold\n",
    "    return df, fitted\n",
    "\n",
    "\n",
    "confidence_df, tuned_log_reg_fitted = compute_confidence_table(\n",
    "    tuned_log_reg,\n",
    "    augmented_embeddings,\n",
    "    records_df[\"category_id\"].values,\n",
    "    label_encoder.classes_,\n",
    "    threshold=0.85,\n",
    ")\n",
    "confidence_df.sort_values(\"confidence\").head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Purpose: List low-confidence cases so reviewers can manually re-label them.\n",
    "low_confidence_cases = confidence_df.query(\"low_confidence\").copy()\n",
    "low_confidence_cases[[\"id\", \"text\", \"pred_label\", \"confidence\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Purpose: Within each predicted class, surface highly similar texts to batch manual review.\n",
    "def find_similar_within_prediction(\n",
    "    base_embeddings: np.ndarray,\n",
    "    ids: Iterable[int],\n",
    "    texts: Iterable[str],\n",
    "    predicted_labels: Iterable[str],\n",
    "    top_k: int = 3,\n",
    "    min_similarity: float = 0.9,\n",
    ") -> List[Dict[str, object]]:\n",
    "    \"\"\"For each sample, return closest neighbors that share the predicted label.\"\"\"\n",
    "    id_array = np.asarray(list(ids))\n",
    "    text_array = np.asarray(list(texts))\n",
    "    label_array = np.asarray(list(predicted_labels))\n",
    "    cos = cosine_similarity(base_embeddings)\n",
    "    groups: List[Dict[str, object]] = []\n",
    "    for idx in range(len(base_embeddings)):\n",
    "        same_mask = label_array == label_array[idx]\n",
    "        candidate_indices = np.where(same_mask)[0]\n",
    "        sims = cos[idx, candidate_indices]\n",
    "        neighbors = []\n",
    "        for candidate_idx, sim in zip(candidate_indices, sims):\n",
    "            if candidate_idx == idx or sim < min_similarity:\n",
    "                continue\n",
    "            neighbors.append(\n",
    "                {\n",
    "                    \"neighbor_id\": int(id_array[candidate_idx]),\n",
    "                    \"similarity\": float(sim),\n",
    "                    \"neighbor_text\": text_array[candidate_idx],\n",
    "                }\n",
    "            )\n",
    "        if neighbors:\n",
    "            neighbors = sorted(neighbors, key=lambda item: item[\"similarity\"], reverse=True)[:top_k]\n",
    "            groups.append(\n",
    "                {\n",
    "                    \"id\": int(id_array[idx]),\n",
    "                    \"pred_label\": label_array[idx],\n",
    "                    \"text\": text_array[idx],\n",
    "                    \"neighbors\": neighbors,\n",
    "                }\n",
    "            )\n",
    "    return groups\n",
    "\n",
    "\n",
    "similar_groups = find_similar_within_prediction(\n",
    "    text_embeddings,\n",
    "    records_df[\"id\"],\n",
    "    records_df[\"text\"],\n",
    "    confidence_df[\"pred_label\"],\n",
    "    top_k=3,\n",
    "    min_similarity=0.92,\n",
    ")\n",
    "similar_groups[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Purpose: Materialize similar-group output as a DataFrame for downstream tooling.\n",
    "similar_groups_df = pd.json_normalize(similar_groups, sep=\".\")\n",
    "similar_groups_df.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shipai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
